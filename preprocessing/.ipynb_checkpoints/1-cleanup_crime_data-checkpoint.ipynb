{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff04e7c4-0ca3-43bf-88c0-2a423aa42fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import pyproj\n",
    "import os\n",
    "os.chdir(\"D:/Projects/crime-prediction\")\n",
    "pyproj.datadir.set_data_dir(\"D:/ProgramData/anaconda3/envs/crime-prediction/Library/share/proj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0391c0b8-079c-4f7f-8e94-571772abc250",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_path = 'data/SPD_Crime_Data__2008-Present_20250710.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f87c1fc6-e3e7-424c-aee5-21036d382aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\crime-prediction\n"
     ]
    }
   ],
   "source": [
    "# read beats data to determine if crime locations are within seattle city limits\n",
    "beats_file =\"data/beats-data.geojson\"\n",
    "beats = gpd.read_file(beats_file)\n",
    "city_limits = gpd.GeoDataFrame(pd.DataFrame({\"City\": \"Seattle\"}, index=[0]), geometry=[beats.geometry.union_all()], crs=\"EPSG:4326\")\n",
    "city_limits_proj = city_limits.to_crs(\"EPSG:32610\")\n",
    "city_limits['centroid'] = city_limits_proj.geometry.centroid.to_crs(city_limits.crs)\n",
    "city_limits.to_csv('data/preprocessed/city-limits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afa11932-d4e3-4894-9ad5-607f36dd6f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data of crimes from seattle crime data\n",
    "def parse_float(value):\n",
    "    if value =='REDACTED':\n",
    "        return -1.0\n",
    "    return float(value)\n",
    "\n",
    "def parse_beat(value):\n",
    "    if value == '-' or value == '99' or value == 'OOJ':\n",
    "        return None\n",
    "    return value\n",
    "\n",
    "def parse_raw_data():\n",
    "    raw_df = pd.read_csv(\n",
    "                         raw_file_path,\n",
    "                         usecols= [\n",
    "                             'Report Number',\n",
    "                             'Offense Date', \n",
    "                             'Report DateTime',\n",
    "                             'Precinct',\n",
    "                             'Offense Category',\n",
    "                             'Latitude',\n",
    "                             'Longitude',\n",
    "                             'Beat',\n",
    "                             'Sector',\n",
    "                             'Precinct',\n",
    "                             'Neighborhood',\n",
    "                             'Reporting Area'\n",
    "                         ],\n",
    "                         parse_dates=['Offense Date', 'Report DateTime'],\n",
    "                         converters={\n",
    "                             'Latitude': parse_float,\n",
    "                             'Longitude': parse_float,\n",
    "                             'Beat': parse_beat\n",
    "                         },                                 \n",
    "                         date_format=\"%m/%d/%Y %I:%M:%S %p\",\n",
    "                         dtype={\n",
    "                             'Precinct': 'category',\n",
    "                             'Offense Category': 'category'\n",
    "                         }\n",
    "                        )\n",
    "    # remove duplicate report numbers\n",
    "    raw_df =  raw_df.drop_duplicates(subset=['Report Number'])\n",
    "    \n",
    "    # convert dates to GMT\n",
    "    always_dst = pd.array([True] * len(raw_df), dtype=pd.BooleanDtype())\n",
    "    raw_df['Offense Date'] = raw_df['Offense Date'].dt.tz_localize('America/Los_Angeles', ambiguous=always_dst).dt.tz_convert('UTC')\n",
    "    raw_df['Report DateTime'] = raw_df['Report DateTime'].dt.tz_localize('America/Los_Angeles', ambiguous=always_dst).dt.tz_convert('UTC')\n",
    "    \n",
    "    # find locations that are outside the seattle city boundary for cleanup\n",
    "    raw_gdf = gpd.GeoDataFrame(raw_df, geometry=gpd.points_from_xy(raw_df[\"Longitude\"], raw_df[\"Latitude\"]), crs=\"EPSG:4326\")\n",
    "    raw_gdf = gpd.sjoin(raw_gdf, city_limits, how=\"left\", predicate=\"within\")\n",
    "    \n",
    "    \n",
    "    # set the latitude and longitude to None for locations outside the city boundary.\n",
    "    # later these latitude and longitude will be sampled from the beat\n",
    "    raw_gdf.loc[pd.notna(raw_gdf['City']) == False, ['Latitude', 'Longitude']] = [None, None]\n",
    "    raw_gdf.drop('index_right', axis=1, inplace=True) \n",
    "    raw_gdf.drop('City', axis=1, inplace=True) \n",
    "    \n",
    "    # drop offenses older than 2008 with report date\n",
    "    raw_gdf = raw_gdf[raw_gdf['Offense Date'].dt.year >= 2008]\n",
    "    raw_gdf.drop('Report DateTime', axis=1, inplace=True) \n",
    "\n",
    "    # get time based attributes\n",
    "    raw_gdf['Hour Sine'] = np.sin(raw_gdf['Offense Date'].dt.hour)\n",
    "    raw_gdf['Hour Cos'] = np.cos(raw_gdf['Offense Date'].dt.hour)\n",
    "    raw_gdf['Day Of Week'] = raw_gdf['Offense Date'].dt.dayofweek\n",
    "    raw_gdf['Weekend'] = (raw_gdf['Day Of Week'] == 5) | (raw_gdf['Day Of Week'] == 6)\n",
    "    raw_gdf['Month'] = raw_df['Offense Date'].dt.month\n",
    "    \n",
    "    print(f\"Raw data count: {len(raw_gdf):,}\")\n",
    "    print(f\"Missing Lat Long data count: {len(raw_gdf.loc[pd.notna(raw_gdf['Latitude']) == False]):,}\")\n",
    "    print(f\"Date Range: {raw_gdf['Offense Date'].min()} to {raw_gdf['Offense Date'].max()}\")\n",
    "    return raw_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b329b6d-d37f-431a-a53a-cd2d38947f7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data count: 1,292,485\n",
      "Missing Lat Long data count: 321,491\n",
      "Date Range: 2008-01-01 00:00:00+00:00 to 2025-07-10 05:52:00+00:00\n"
     ]
    }
   ],
   "source": [
    "raw_gdf = parse_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8529c4b2-1f4b-4106-98b8-6c9f0f054d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_point_in_beat(beat_polygon):\n",
    "    min_x, min_y, max_x, max_y = beat_polygon.bounds\n",
    "    while True:\n",
    "        point = Point(random.uniform(min_x, max_x), random.uniform(min_y, max_y))\n",
    "        if beat_polygon.contains(point):\n",
    "            return point\n",
    "            \n",
    "def fill_missing_coordinates(df, beats_gdf):\n",
    "    beat_polygons = beats.set_index('name')['geometry']\n",
    "    points =  df.loc[pd.notna(df['Latitude']) == False, 'Beat'].map(\n",
    "        lambda x: sample_point_in_beat(beat_polygons[x]) if pd.notna(x) else None\n",
    "    )\n",
    "    df.loc[pd.notna(df['Latitude']) == False, 'Latitude'] = points.apply(lambda p: p.y if p else None)\n",
    "    df.loc[pd.notna(df['Longitude']) == False, 'Longitude'] = points.apply(lambda p: p.x if p else None)\n",
    "    df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df[\"Longitude\"], df[\"Latitude\"]), crs=\"EPSG:4326\")\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e36b37a-787b-4af2-a3e8-6a5c1a1744a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with missing location count: 12,481\n"
     ]
    }
   ],
   "source": [
    "raw_gdf = fill_missing_coordinates(raw_gdf, beats)\n",
    "print(f\"Data with missing location count: {len(raw_gdf.loc[pd.notna(raw_gdf['Latitude']) == False]):,}\")\n",
    "raw_gdf = raw_gdf.loc[pd.notna(raw_gdf['Latitude'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0a690b9-3482-412b-8058-80c3958a16d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_gdf.to_csv('data/preprocessed/preprocessed-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566341fb-88d1-4359-a465-cb8c93707845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crime-prediction",
   "language": "python",
   "name": "crime-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
